{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from requests_html import HTMLSession, AsyncHTMLSession\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Variables\n",
    "date_string = datetime.today().strftime('%Y%m%d')\n",
    "weekStart = 1\n",
    "weekEnd = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dictionary of IDs\n",
    "ids = pd.read_csv('db/id_dict.csv', dtype={'player_id':'str'})\n",
    "ids = ids[['full_name', 'player_id', 'id_sharks', 'id_ourlads']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Sleeper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processPlayers():\n",
    "    # Use requests_html to get players since sleeper-py seems to be broken here\n",
    "    session = HTMLSession()\n",
    "    r = session.get('https://api.sleeper.app/v1/players/nfl')\n",
    "    df = pd.DataFrame(json.loads(r.html.html)).T\n",
    "    df = df[[\n",
    "        'player_id', 'full_name','birth_date','age','weight', 'height',\n",
    "        'team','position','fantasy_positions','depth_chart_order','depth_chart_position',\n",
    "        'status', 'injury_status','injury_notes','injury_start_date', 'practice_participation', 'practice_description',\n",
    "        'years_exp',\n",
    "        'active',\n",
    "    ]]\n",
    "    df = df.loc[df['position'].isin(['QB','RB','WR','TE','K','P','DEF'])]\n",
    "    df.loc[df['position'].isin(['P', 'K']), 'position'] = 'PK'\n",
    "    df.loc[df['position']=='DEF', 'full_name'] = df.loc[df['position']=='DEF', 'team']\n",
    "    return df\n",
    "\n",
    "# Get info on all players\n",
    "players = processPlayers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Fantasy Sharks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Fantasy Sharks predictions\n",
    "session = AsyncHTMLSession()\n",
    "sharks = pd.DataFrame()\n",
    "\n",
    "# Loop through weeks and positions\n",
    "posList = ['1','2','4','5','7','15','6']\n",
    "weekList = [str(int(x)) for x in np.linspace(787, 804, 18)]\n",
    "for posKey in posList:\n",
    "    for weekKey in weekList[(weekStart-1):weekEnd]:\n",
    "        url = f'https://www.fantasysharks.com/apps/bert/forecasts/projections.php?League=&Position={posKey}&scoring=2&Segment={weekKey}&uid=4'\n",
    "        # Scrape\n",
    "        r = await session.get(url)\n",
    "        await r.html.arender()\n",
    "        element = r.html.find('#toolData')[0].html\n",
    "        # Convert to df\n",
    "        df = pd.read_html(element)[0]\n",
    "        df = df.loc[df['#'].str.isnumeric()]\n",
    "        df['Week'] = int(weekKey) - 786\n",
    "        sharks = pd.concat([sharks, df], axis=0, ignore_index=True)\n",
    "        time.sleep(5)\n",
    "        \n",
    "# Convert raw prediction values to numeric\n",
    "colList = ['Att', 'Comp', 'Pass Yds', 'Pass TDs', 'Int', 'Sck', 'Rush', 'Rsh Yds', 'Rsh TDs', 'Fum', 'Tgt', \\\n",
    "    'RZ Tgt', 'Rec', 'Rec Yds', 'Rec TDs', 'Kick Ret Yds', 'XPM', 'XPA', 'FGM', 'FGA', '10-19 FGM', '20-29 FGM', \\\n",
    "        '30-39 FGM', '40-49 FGM', '50+ FGM', 'Miss', 'Yds Allowed', 'Pts Agn', 'Scks', 'DefTD', 'Safts']\n",
    "for col in colList:\n",
    "    sharks[col] = sharks[col].astype('float64')\n",
    "    \n",
    "# Clean up\n",
    "sharks = sharks.rename(columns={'Week':'week'})\n",
    "# Create ID: Remove Rookie \"R\": format first name last name\n",
    "cond1 = sharks['Player'].str[-1]==\"R\"\n",
    "sharks.loc[cond1, 'Player'] = sharks.loc[cond1, 'Player'].str[:-1]\n",
    "sharks['lName'] = sharks['Player'].str.split(\", \", expand=True)[0]\n",
    "sharks['fName'] = sharks['Player'].str.split(\", \", expand=True)[1]\n",
    "sharks['id_sharks'] = sharks['fName']+\" \"+sharks['lName']\n",
    "sharks['id_sharks'] = sharks['id_sharks'].str.replace(\".\", \"\")\n",
    "sharks['id_sharks'] = sharks['id_sharks'].str.title()\n",
    "sharks['id_sharks'] = [\" \".join(x.split(\" \")[:2]) for x in sharks['id_sharks']]\n",
    "# Reduce\n",
    "sharks = sharks[['id_sharks', 'week']+colList]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Ourlads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get OurLads data about punt/kick returners\n",
    "session = AsyncHTMLSession()\n",
    "\n",
    "# Get page\n",
    "r = await session.get(\"https://www.ourlads.com/nfldepthcharts/depthcharts.aspx\")\n",
    "await r.html.arender()\n",
    "\n",
    "element = r.html.find('#ctl00_phContent_gvChart')[0].html\n",
    "\n",
    "# Convert to dataframe\n",
    "ourlads = pd.read_html(element)[0]\n",
    "# Filter for only the needed columns\n",
    "ourlads = ourlads[['Team', 'Pos', 'Player 1', 'Player 2', 'Player 3', 'Player 4', 'Player 5']]\n",
    "# Rename columns of Position Ranks; limit number of ranks to three\n",
    "ourlads = ourlads.rename(columns={\n",
    "    'Player 1':'1',\n",
    "    'Player 2':'2',\n",
    "    'Player 3':'3',\n",
    "    'Player 4':'3',\n",
    "    'Player 5':'3',\n",
    "})\n",
    "# Filter only relevant positions\n",
    "posList = ['LWR', 'RWR', 'SWR', 'TE', 'QB', 'RB', 'PK', 'PR', 'KR', 'RES']\n",
    "ourlads = ourlads.loc[ourlads['Pos'].isin(posList)]\n",
    "\n",
    "# Transpose columns to rows to get position ranks in row form rather than column\n",
    "ourlads = ourlads.melt(id_vars=[\"Team\", \"Pos\"], \n",
    "    var_name=\"posRank\", \n",
    "    value_name=\"playerName\")\n",
    "    # Rename columns to match MyFantasyLeague\n",
    "ourlads = ourlads.rename(columns={'Team':'team', 'Pos':'pos'})\n",
    "# Create id_ourlads column\n",
    "ourlads = ourlads.dropna(subset='playerName')\n",
    "ourlads['lName'] = ourlads['playerName'].str.split(\", \", expand=True)[0]\n",
    "ourlads['fName'] = ourlads['playerName'].str.split(\", \", expand=True)[1].str.split(\" \", expand=True)[0]\n",
    "ourlads['id_ourlads'] = ourlads['fName'] + \" \" + ourlads['lName']\n",
    "ourlads['id_ourlads'] = ourlads['id_ourlads'].str.replace(\".\", \"\")\n",
    "ourlads['id_ourlads'] = ourlads['id_ourlads'].str.title()\n",
    "ourlads['id_ourlads'] = [\" \".join(x.split(\" \")[:2]) for x in ourlads['id_ourlads']]\n",
    "\n",
    "# Highlight PR & KRs\n",
    "cond1 = ourlads['pos']=='PR'\n",
    "cond2 = ourlads['pos']=='KR'\n",
    "cond3 = ourlads['posRank']==\"1\"\n",
    "prs = ourlads.loc[cond1 & cond3]['id_ourlads'].unique()\n",
    "krs = ourlads.loc[cond2 & cond3]['id_ourlads'].unique()\n",
    "ourlads.loc[ourlads['id_ourlads'].isin(prs), 'PR'] = True\n",
    "ourlads.loc[ourlads['id_ourlads'].isin(krs), 'KR'] = True\n",
    "\n",
    "# Reduce\n",
    "ourlads = ourlads.loc[(ourlads['PR']==True) | (ourlads['KR']==True)]\n",
    "ourlads = ourlads.drop_duplicates(subset='id_ourlads', ignore_index=True)\n",
    "ourlads = ourlads[['id_ourlads', 'PR', 'KR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create predictions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions dataset\n",
    "preds = players \\\n",
    "    .merge(ids[['player_id', 'id_sharks', 'id_ourlads']], how='left', on='player_id') \\\n",
    "    .merge(sharks, how='left', on='id_sharks') \\\n",
    "    .merge(ourlads, how='left', on='id_ourlads')\n",
    "preds['date_prediction'] = date_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flag any players who need to be added to the id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Flag previously unknown players\n",
    "cond1 = ~players['player_id'].isin(ids['player_id'])\n",
    "cond2 = players['full_name']!=\"Player Invalid\"\n",
    "unknowns = players.loc[cond1 & cond2]\n",
    "print(len(unknowns))\n",
    "if len(unknowns)>0:\n",
    "    unknowns.to_csv('db/unknowns.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read old data\n",
    "preds_db = pd.read_csv('db/records_preds.csv')\n",
    "# Update\n",
    "preds_db = preds_db.loc[preds_db['date_prediction']!=date_string]\n",
    "preds_db = pd.concat([preds_db, preds], axis=0, ignore_index=False)\n",
    "# Write new data\n",
    "preds_db.to_csv('db/records_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('fnfl2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d5343d8487a7ad33f7c6df21cec71a8cada15334439bd483feb9f981d44372f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
